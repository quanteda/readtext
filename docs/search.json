[{"path":"https://readtext.quanteda.io/CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (http:contributor-covenant.org), version 1.0.0, available http://contributor-covenant.org/version/1/0/0/","code":""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"1. Introduction","title":"Reading text files with readtext","text":"vignette walks importing variety different text files R using readtext package. Currently, readtext supports plain text files (.txt), data form JavaScript Object Notation (.json), comma-tab-separated values (.csv, .tab, .tsv), XML documents (.xml), well PDF Microsoft Word formatted files (.pdf, .doc, .docx). readtext also handles multiple files file types using instance “glob” expression, files URL archive file (.zip, .tar, .tar.gz, .tar.bz). Usually, determine format files explicitly - readtext takes information file ending. readtext package comes data directory called extdata contains examples files listed . vignette, use data directory. extdata directory contains several subfolders include different text files. following examples, load one files stored folders. paste0 command used concatenate extdata folder readtext package subfolders. reading custom text files, need determine data directory (see ?setwd()).","code":"# Get the data directory from readtext DATA_DIR <- system.file(\"extdata/\", package = \"readtext\")"},{"path":[]},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"plain-text-files--txt","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.1 Plain text files (.txt)","title":"Reading text files with readtext","text":"folder “txt” contains subfolder named UDHR .txt files Universal Declaration Human Rights 13 languages. can specify document-level metadata (docvars) based file names separate data.frame. take docvars filenames (docvarsfrom = \"filenames\") set names variable (docvarnames = c(\"unit\", \"context\", \"year\", \"language\", \"party\")). command dvsep = \"_\" determines separator (regular expression character string) included filenames delimit docvar elements. readtext can also curse subdirectories. example, folder txt/movie_reviews contains two subfolders (called neg pos). can load texts included folders.","code":"# Read in all files from a folder readtext(paste0(DATA_DIR, \"/txt/UDHR/*\")) ## readtext object consisting of 13 documents and 0 docvars. ## $text ##  [1] \"\\033[38;5;246m# A data frame: 13 × 2\\033[39m\"                                                                                ##  [2] \"  doc_id            text                         \"                                                                           ##  [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m             \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m                        \" ##  [4] \"\\033[38;5;250m1\\033[39m UDHR_chinese.txt  \\033[38;5;246m\\\"\\033[39m\\\\\\\"世界人权宣言\\\\n联合国\\\\\\\"...\\033[38;5;246m\\\"\\033[39m\"  ##  [5] \"\\033[38;5;250m2\\033[39m UDHR_czech.txt    \\033[38;5;246m\\\"\\033[39m\\\\\\\"VŠEOBECNÁ \\\\\\\"...\\033[38;5;246m\\\"\\033[39m          \"   ##  [6] \"\\033[38;5;250m3\\033[39m UDHR_danish.txt   \\033[38;5;246m\\\"\\033[39m\\\\\\\"Den 10. de\\\\\\\"...\\033[38;5;246m\\\"\\033[39m          \"   ##  [7] \"\\033[38;5;250m4\\033[39m UDHR_english.txt  \\033[38;5;246m\\\"\\033[39m\\\\\\\"Universal \\\\\\\"...\\033[38;5;246m\\\"\\033[39m          \"   ##  [8] \"\\033[38;5;250m5\\033[39m UDHR_french.txt   \\033[38;5;246m\\\"\\033[39m\\\\\\\"Déclaratio\\\\\\\"...\\033[38;5;246m\\\"\\033[39m          \"   ##  [9] \"\\033[38;5;250m6\\033[39m UDHR_georgian.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"FLFVBFYBC \\\\\\\"...\\033[38;5;246m\\\"\\033[39m          \"   ## [10] \"\\033[38;5;246m# ℹ 7 more rows\\033[39m\"                                                                                       ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\" # Manifestos with docvars from filenames readtext(paste0(DATA_DIR, \"/txt/EU_manifestos/*.txt\"),          docvarsfrom = \"filenames\",           docvarnames = c(\"unit\", \"context\", \"year\", \"language\", \"party\"),          dvsep = \"_\",           encoding = \"ISO-8859-1\") ## readtext object consisting of 17 documents and 5 docvars. ## $text ##  [1] \"\\033[38;5;246m# A data frame: 17 × 7\\033[39m\"                                                                                                                                                                                                                                                                                                        ##  [2] \"  doc_id                  text                unit  context  year language party\"                                                                                                                                                                                                                                                                    ##  [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m                   \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m               \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m   \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m\" ##  [4] \"\\033[38;5;250m1\\033[39m EU_euro_2004_de_PSE.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"PES · PSE \\\\\\\"...\\033[38;5;246m\\\"\\033[39m EU    euro     \\033[4m2\\033[24m004 de       PSE  \"                                                                                                                                                                             ##  [5] \"\\033[38;5;250m2\\033[39m EU_euro_2004_de_V.txt   \\033[38;5;246m\\\"\\033[39m\\\\\\\"Gemeinsame\\\\\\\"...\\033[38;5;246m\\\"\\033[39m EU    euro     \\033[4m2\\033[24m004 de       V    \"                                                                                                                                                                             ##  [6] \"\\033[38;5;250m3\\033[39m EU_euro_2004_en_PSE.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"PES · PSE \\\\\\\"...\\033[38;5;246m\\\"\\033[39m EU    euro     \\033[4m2\\033[24m004 en       PSE  \"                                                                                                                                                                             ##  [7] \"\\033[38;5;250m4\\033[39m EU_euro_2004_en_V.txt   \\033[38;5;246m\\\"\\033[39m\\\\\\\"Manifesto\\\\n\\\\\\\"..… EU    euro     \\033[4m2\\033[24m004 en       V    \"                                                                                                                                                                                                   ##  [8] \"\\033[38;5;250m5\\033[39m EU_euro_2004_es_PSE.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"PES · PSE \\\\\\\"...\\033[38;5;246m\\\"\\033[39m EU    euro     \\033[4m2\\033[24m004 es       PSE  \"                                                                                                                                                                             ##  [9] \"\\033[38;5;250m6\\033[39m EU_euro_2004_es_V.txt   \\033[38;5;246m\\\"\\033[39m\\\\\\\"Manifesto\\\\n\\\\\\\"..… EU    euro     \\033[4m2\\033[24m004 es       V    \"                                                                                                                                                                                                   ## [10] \"\\033[38;5;246m# ℹ 11 more rows\\033[39m\"                                                                                                                                                                                                                                                                                                              ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\" # Recurse through subdirectories readtext(paste0(DATA_DIR, \"/txt/movie_reviews/*\")) ## readtext object consisting of 10 documents and 0 docvars. ## $text ##  [1] \"\\033[38;5;246m# A data frame: 10 × 2\\033[39m\"                                                                         ##  [2] \"  doc_id              text                \"                                                                           ##  [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m               \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m               \" ##  [4] \"\\033[38;5;250m1\\033[39m neg_cv000_29416.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"plot : two\\\\\\\"...\\033[38;5;246m\\\"\\033[39m \"   ##  [5] \"\\033[38;5;250m2\\033[39m neg_cv001_19502.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"the happy \\\\\\\"...\\033[38;5;246m\\\"\\033[39m \"   ##  [6] \"\\033[38;5;250m3\\033[39m neg_cv002_17424.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"it is movi\\\\\\\"...\\033[38;5;246m\\\"\\033[39m \"   ##  [7] \"\\033[38;5;250m4\\033[39m neg_cv003_12683.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\" \\\\\\\" quest f\\\\\\\"...\\033[38;5;246m\\\"\\033[39m\" ##  [8] \"\\033[38;5;250m5\\033[39m neg_cv004_12641.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"synopsis :\\\\\\\"...\\033[38;5;246m\\\"\\033[39m \"   ##  [9] \"\\033[38;5;250m6\\033[39m pos_cv000_29590.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"films adap\\\\\\\"...\\033[38;5;246m\\\"\\033[39m \"   ## [10] \"\\033[38;5;246m# ℹ 4 more rows\\033[39m\"                                                                                ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"comma--or-tab-separated-values--csv--tab--tsv","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.2 Comma- or tab-separated values (.csv, .tab, .tsv)","title":"Reading text files with readtext","text":"Read comma separated values (.csv files) contain textual data. determine texts variable .csv file text_field. column contains actual text. columns original csv file (Year, President, FirstName) default treated document-level variables. procedure applies tab-separated values.","code":"# Read in comma-separated values readtext(paste0(DATA_DIR, \"/csv/inaugCorpus.csv\"), text_field = \"texts\") ## readtext object consisting of 5 documents and 3 docvars. ## $text ## [1] \"\\033[38;5;246m# A data frame: 5 × 5\\033[39m\"                                                                                                                                                                                                                 ## [2] \"  doc_id            text                 Year President  FirstName\"                                                                                                                                                                                          ## [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m             \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m               \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m      \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \" ## [4] \"\\033[38;5;250m1\\033[39m inaugCorpus.csv.1 \\033[38;5;246m\\\"\\033[39m\\\\\\\"Fellow-Cit\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m789 Washington George   \"                                                                                                   ## [5] \"\\033[38;5;250m2\\033[39m inaugCorpus.csv.2 \\033[38;5;246m\\\"\\033[39m\\\\\\\"Fellow cit\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m793 Washington George   \"                                                                                                   ## [6] \"\\033[38;5;250m3\\033[39m inaugCorpus.csv.3 \\033[38;5;246m\\\"\\033[39m\\\\\\\"When it wa\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m797 Adams      John     \"                                                                                                   ## [7] \"\\033[38;5;250m4\\033[39m inaugCorpus.csv.4 \\033[38;5;246m\\\"\\033[39m\\\\\\\"Friends an\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m801 Jefferson  Thomas   \"                                                                                                   ## [8] \"\\033[38;5;250m5\\033[39m inaugCorpus.csv.5 \\033[38;5;246m\\\"\\033[39m\\\\\\\"Proceeding\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m805 Jefferson  Thomas   \"                                                                                                   ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\" # Read in tab-separated values readtext(paste0(DATA_DIR, \"/tsv/dailsample.tsv\"), text_field = \"speech\") ## readtext object consisting of 33 documents and 9 docvars. ## $text ##  [1] \"\\033[38;5;246m# A data frame: 33 × 11\\033[39m\"                                                                                                                                                                                                                                                                                                                                                                                 ##  [2] \"  doc_id         text  speechID memberID partyID constID title date  member_name\"                                                                                                                                                                                                                                                                                                                                              ##  [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m          \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m    \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m   \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m   \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m      \" ##  [4] \"\\033[38;5;250m1\\033[39m dailsample.ts… \\033[38;5;246m\\\"\\033[39m\\\\\\\"M…        1      977      22     158 1. C… 1919… Count Geor…\"                                                                                                                                                                                                                                                                                               ##  [5] \"\\033[38;5;250m2\\033[39m dailsample.ts… \\033[38;5;246m\\\"\\033[39m\\\\\\\"I…        2     \\033[4m1\\033[24m603      22     103 1. C… 1919… Mr. Pádrai…\"                                                                                                                                                                                                                                                                                ##  [6] \"\\033[38;5;250m3\\033[39m dailsample.ts… \\033[38;5;246m\\\"\\033[39m\\\\\\\"'…        3      116      22     178 1. C… 1919… Mr. Cathal…\"                                                                                                                                                                                                                                                                                               ##  [7] \"\\033[38;5;250m4\\033[39m dailsample.ts… \\033[38;5;246m\\\"\\033[39m\\\\\\\"T…        4      116      22     178 2. C… 1919… Mr. Cathal…\"                                                                                                                                                                                                                                                                                               ##  [8] \"\\033[38;5;250m5\\033[39m dailsample.ts… \\033[38;5;246m\\\"\\033[39m\\\\\\\"L…        5      116      22     178 3. A… 1919… Mr. Cathal…\"                                                                                                                                                                                                                                                                                               ##  [9] \"\\033[38;5;250m6\\033[39m dailsample.ts… \\033[38;5;246m\\\"\\033[39m\\\\\\\"-…        6      116      22     178 3. A… 1919… Mr. Cathal…\"                                                                                                                                                                                                                                                                                               ## [10] \"\\033[38;5;246m# ℹ 27 more rows\\033[39m\"                                                                                                                                                                                                                                                                                                                                                                                        ## [11] \"\\033[38;5;246m# ℹ 2 more variables: party_name <chr>, const_name <chr>\\033[39m\"                                                                                                                                                                                                                                                                                                                                                ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"json-data--json","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.3 JSON data (.json)","title":"Reading text files with readtext","text":"can also read .json data. need specify text_field.","code":"## Read in JSON data readtext(paste0(DATA_DIR, \"/json/inaugural_sample.json\"), text_field = \"texts\") ## readtext object consisting of 3 documents and 3 docvars. ## $text ## [1] \"\\033[38;5;246m# A data frame: 3 × 5\\033[39m\"                                                                                                                                                                                                                       ## [2] \"  doc_id                  text                 Year President  FirstName\"                                                                                                                                                                                          ## [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m                   \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m               \\033[3m\\033[38;5;246m<int>\\033[39m\\033[23m \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m      \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \" ## [4] \"\\033[38;5;250m1\\033[39m inaugural_sample.json.1 \\033[38;5;246m\\\"\\033[39m\\\\\\\"Fellow-Cit\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m789 Washington George   \"                                                                                                   ## [5] \"\\033[38;5;250m2\\033[39m inaugural_sample.json.2 \\033[38;5;246m\\\"\\033[39m\\\\\\\"Fellow cit\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m793 Washington George   \"                                                                                                   ## [6] \"\\033[38;5;250m3\\033[39m inaugural_sample.json.3 \\033[38;5;246m\\\"\\033[39m\\\\\\\"When it wa\\\\\\\"...\\033[38;5;246m\\\"\\033[39m  \\033[4m1\\033[24m797 Adams      John     \"                                                                                                   ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"pdf-files","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.4 PDF files","title":"Reading text files with readtext","text":"readtext can also read convert .pdf files. example load .pdf files stored UDHR folder, determine docvars shall taken filenames. call document-level variables document language, specify delimiter (dvsep).","code":"## Read in Universal Declaration of Human Rights pdf files (rt_pdf <- readtext(paste0(DATA_DIR, \"/pdf/UDHR/*.pdf\"),                      docvarsfrom = \"filenames\",                      docvarnames = c(\"document\", \"language\"),                     sep = \"_\")) ## readtext object consisting of 11 documents and 2 docvars. ## $text ##  [1] \"\\033[38;5;246m# A data frame: 11 × 4\\033[39m\"                                                                                                                                                                           ##  [2] \"  doc_id           text                          document language\"                                                                                                                                                     ##  [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m            \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m                         \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m   \" ##  [4] \"\\033[38;5;250m1\\033[39m UDHR_chinese.pdf \\033[38;5;246m\\\"\\033[39m\\\\\\\"世界人权宣言\\\\n\\\\n联合\\\\\\\"...\\033[38;5;246m\\\"\\033[39m UDHR     chinese \"                                                                           ##  [5] \"\\033[38;5;250m2\\033[39m UDHR_czech.pdf   \\033[38;5;246m\\\"\\033[39m\\\\\\\"VŠEOBECNÁ \\\\\\\"...\\033[38;5;246m\\\"\\033[39m           UDHR     czech   \"                                                                             ##  [6] \"\\033[38;5;250m3\\033[39m UDHR_danish.pdf  \\033[38;5;246m\\\"\\033[39m\\\\\\\"Den 10. de\\\\\\\"...\\033[38;5;246m\\\"\\033[39m           UDHR     danish  \"                                                                             ##  [7] \"\\033[38;5;250m4\\033[39m UDHR_english.pdf \\033[38;5;246m\\\"\\033[39m\\\\\\\"Universal \\\\\\\"...\\033[38;5;246m\\\"\\033[39m           UDHR     english \"                                                                             ##  [8] \"\\033[38;5;250m5\\033[39m UDHR_french.pdf  \\033[38;5;246m\\\"\\033[39m\\\\\\\"Déclaratio\\\\\\\"...\\033[38;5;246m\\\"\\033[39m           UDHR     french  \"                                                                             ##  [9] \"\\033[38;5;250m6\\033[39m UDHR_greek.pdf   \\033[38;5;246m\\\"\\033[39m\\\\\\\"ΟΙΚΟΥΜΕΝΙΚ\\\\\\\"...\\033[38;5;246m\\\"\\033[39m           UDHR     greek   \"                                                                             ## [10] \"\\033[38;5;246m# ℹ 5 more rows\\033[39m\"                                                                                                                                                                                  ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"microsoft-word-files--doc--docx","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.5 Microsoft Word files (.doc, .docx)","title":"Reading text files with readtext","text":"Microsoft Word formatted files converted package antiword older .doc files, using XML newer .docx files.","code":"## Read in Word data (.docx) readtext(paste0(DATA_DIR, \"/word/*.docx\")) ## readtext object consisting of 2 documents and 0 docvars. ## $text ## [1] \"\\033[38;5;246m# A data frame: 2 × 2\\033[39m\"                                                                                 ## [2] \"  doc_id                      text               \"                                                                           ## [3] \"  \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m                       \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m              \" ## [4] \"\\033[38;5;250m1\\033[39m UK_2015_EccentricParty.docx \\033[38;5;246m\\\"\\033[39m\\\\\\\"The Eccent\\\\\\\"...\\033[38;5;246m\\\"\\033[39m\"   ## [5] \"\\033[38;5;250m2\\033[39m UK_2015_LoonyParty.docx     \\033[38;5;246m\\\"\\033[39m\\\\\\\"The Offici\\\\\\\"...\\033[38;5;246m\\\"\\033[39m\"   ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"text-from-urls","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.6 Text from URLs","title":"Reading text files with readtext","text":"can also read text directly URL.","code":"# Note: Example required: which URL should we use?"},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"text-from-archive-files--zip--tar--tar-gz--tar-bz","dir":"Articles","previous_headings":"2. Reading one or more text files","what":"2.7 Text from archive files (.zip, .tar, .tar.gz, .tar.bz)","title":"Reading text files with readtext","text":"Finally, possible include text archives.","code":"# Note: Archive file required. The only zip archive included in readtext has  # different encodings and is difficult to import (see section 4.2)."},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"inter-operability-with-quanteda","dir":"Articles","previous_headings":"","what":"3. Inter-operability with quanteda","title":"Reading text files with readtext","text":"readtext originally developed early versions quanteda package quantitative analysis textual data. spawned textfile() function package, now lives exclusively readtext. quanteda’s corpus constructor recognizes data.frame format returned readtext(), can construct corpus directly readtext object, preserving docvars meta-data. can easily construct corpus readtext object.","code":"if (require(\"quanteda\")) {  # read in comma-separated values with readtext rt_csv <- readtext(paste0(DATA_DIR, \"/csv/inaugCorpus.csv\"), text_field = \"texts\")  # create quanteda corpus corpus_csv <- corpus(rt_csv) summary(corpus_csv, 5) } ## Loading required package: quanteda ## Package version: 4.3.1 ## Unicode version: 14.0 ## ICU version: 71.1 ## Parallel computing: 10 of 10 threads used. ## See https://quanteda.io for tutorials and examples. ##  ## Attaching package: 'quanteda' ## The following object is masked from 'package:readtext': ##  ##     texts ## Corpus consisting of 5 documents, showing 5 documents: ##  ##               Text Types Tokens Sentences Year  President FirstName ##  inaugCorpus.csv.1   625   1540        23 1789 Washington    George ##  inaugCorpus.csv.2    96    147         4 1793 Washington    George ##  inaugCorpus.csv.3   826   2578        37 1797      Adams      John ##  inaugCorpus.csv.4   717   1927        41 1801  Jefferson    Thomas ##  inaugCorpus.csv.5   804   2381        45 1805  Jefferson    Thomas"},{"path":[]},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"remove-page-numbers-using-regular-expressions","dir":"Articles","previous_headings":"4. Solving common problems","what":"4.1 Remove page numbers using regular expressions","title":"Reading text files with readtext","text":"document contains page numbers, imported well. want remove , can use regular expression. strongly recommend using stringi package. common regular expressions can look cheatsheet. first need check original file format page numbers occur (e.g., “1”, “-1-”, “page 1” etc.). can make use fact page numbers almost always preceded followed linebreak (\\n). loading text readtext, can replace page numbers. first example, page numbers format “page X”. second example remove page numbers format “- X -”. stringi functions can also applied readtext objects.","code":"# Load stringi package require(\"stringi\") # Make some text with page numbers sample_text_a <- \"The quick brown fox named Seamus jumps over the lazy dog also named Seamus,  page 1  with the newspaper from a boy named quick Seamus, in his mouth. page 2 The quicker brown fox jumped over 2 lazy dogs.\"  sample_text_a ## [1] \"The quick brown fox named Seamus jumps over the lazy dog also named Seamus, \\npage 1 \\nwith the newspaper from a boy named quick Seamus, in his mouth.\\npage 2\\nThe quicker brown fox jumped over 2 lazy dogs.\"  # Remove \"page\" and respective digit sample_text_a2 <- unlist(stri_split_fixed(sample_text_a, '\\n'), use.names = FALSE) sample_text_a2 <- stri_replace_all_regex(sample_text_a2, \"page \\\\d*\", \"\") sample_text_a2 <- stri_trim_both(sample_text_a2) sample_text_a2 <- sample_text_a2[sample_text_a2 != ''] stri_paste(sample_text_a2, collapse = '\\n') ## [1] \"The quick brown fox named Seamus jumps over the lazy dog also named Seamus,\\nwith the newspaper from a boy named quick Seamus, in his mouth.\\nThe quicker brown fox jumped over 2 lazy dogs.\" sample_text_b <- \"The quick brown fox named Seamus  - 1 -  jumps over the lazy dog also named Seamus, with  - 2 -  the newspaper from a boy named quick Seamus, in his mouth.  - 33 -  The quicker brown fox jumped over 2 lazy dogs.\"  sample_text_b ## [1] \"The quick brown fox named Seamus \\n- 1 - \\njumps over the lazy dog also named Seamus, with \\n- 2 - \\nthe newspaper from a boy named quick Seamus, in his mouth. \\n- 33 - \\nThe quicker brown fox jumped over 2 lazy dogs.\"  sample_text_b2 <- unlist(stri_split_fixed(sample_text_b, '\\n'), use.names = FALSE) sample_text_b2 <- stri_replace_all_regex(sample_text_b2, \"[-] \\\\d* [-]\", \"\") sample_text_b2 <- stri_trim_both(sample_text_b2) sample_text_b2 <- sample_text_b2[sample_text_b2 != ''] stri_paste(sample_text_b2, collapse = '\\n') ## [1] \"The quick brown fox named Seamus\\njumps over the lazy dog also named Seamus, with\\nthe newspaper from a boy named quick Seamus, in his mouth.\\nThe quicker brown fox jumped over 2 lazy dogs.\""},{"path":"https://readtext.quanteda.io/articles/readtext_vignette.html","id":"read-files-with-different-encodings","dir":"Articles","previous_headings":"4. Solving common problems","what":"4.2 Read files with different encodings","title":"Reading text files with readtext","text":"Sometimes files type different encodings. encoding file included file name, can extract information import texts correctly. , get encoding filenames . read text files without specifying encoding, get erroneously formatted text. avoid , determine encoding using character object fileencoding created . can also add docvars based filenames. file can easily create quanteda corpus object.","code":"# create a temporary directory to extract the .zip file FILEDIR <- tempdir() # unzip file unzip(system.file(\"extdata\", \"data_files_encodedtexts.zip\", package = \"readtext\"), exdir = FILEDIR) # get encoding from filename filenames <- list.files(FILEDIR, \"^(Indian|UDHR_).*\\\\.txt$\")  head(filenames) ## [1] \"IndianTreaty_English_UTF-16LE.txt\"  \"IndianTreaty_English_UTF-8-BOM.txt\" ## [3] \"UDHR_Arabic_ISO-8859-6.txt\"         \"UDHR_Arabic_UTF-8.txt\"              ## [5] \"UDHR_Arabic_WINDOWS-1256.txt\"       \"UDHR_Chinese_GB2312.txt\"  # Strip the extension filenames <- gsub(\".txt$\", \"\", filenames) parts <- strsplit(filenames, \"_\") fileencodings <- sapply(parts, \"[\", 3)  head(fileencodings) ## [1] \"UTF-16LE\"     \"UTF-8-BOM\"    \"ISO-8859-6\"   \"UTF-8\"        \"WINDOWS-1256\" ## [6] \"GB2312\"  # Check whether certain file encodings are not supported notAvailableIndex <- which(!(fileencodings %in% iconvlist())) fileencodings[notAvailableIndex] ## [1] \"UTF-8-BOM\" txts <- readtext(paste0(DATA_DIR, \"/data_files_encodedtexts.zip\"),                   encoding = fileencodings,                  docvarsfrom = \"filenames\",                   docvarnames = c(\"document\", \"language\", \"input_encoding\")) print(txts, n = 50) ## readtext object consisting of 36 documents and 3 docvars. ## $text ##  [1] \"\\033[38;5;246m# A data frame: 36 × 5\\033[39m\"                                                                                                                                                                                                                              ##  [2] \"   doc_id                             text      document language input_encoding\"                                                                                                                                                                                          ##  [3] \"   \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m                              \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m     \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m    \\033[3m\\033[38;5;246m<chr>\\033[39m\\033[23m         \" ##  [4] \"\\033[38;5;250m 1\\033[39m IndianTreaty_English_UTF-16LE.txt  \\033[38;5;246m\\\"\\033[39m\\\\\\\"WHERE… IndianT… English  UTF-16LE      \"                                                                                                                                           ##  [5] \"\\033[38;5;250m 2\\033[39m IndianTreaty_English_UTF-8-BOM.txt \\033[38;5;246m\\\"\\033[39m\\\\\\\"ARTIC… IndianT… English  UTF-8-BOM     \"                                                                                                                                           ##  [6] \"\\033[38;5;250m 3\\033[39m UDHR_Arabic_ISO-8859-6.txt         \\033[38;5;246m\\\"\\033[39m\\\\\\\"الديب… UDHR     Arabic   ISO-8859-6    \"                                                                                                                                           ##  [7] \"\\033[38;5;250m 4\\033[39m UDHR_Arabic_UTF-8.txt              \\033[38;5;246m\\\"\\033[39m\\\\\\\"الديب… UDHR     Arabic   UTF-8         \"                                                                                                                                           ##  [8] \"\\033[38;5;250m 5\\033[39m UDHR_Arabic_WINDOWS-1256.txt       \\033[38;5;246m\\\"\\033[39m\\\\\\\"الديب… UDHR     Arabic   WINDOWS-1256  \"                                                                                                                                           ##  [9] \"\\033[38;5;250m 6\\033[39m UDHR_Chinese_GB2312.txt            \\033[38;5;246m\\\"\\033[39m\\\\\\\"世界人权宣… UDHR     Chinese  GB2312        \"                                                                                                                                      ## [10] \"\\033[38;5;250m 7\\033[39m UDHR_Chinese_GBK.txt               \\033[38;5;246m\\\"\\033[39m\\\\\\\"世界人权宣… UDHR     Chinese  GBK           \"                                                                                                                                      ## [11] \"\\033[38;5;250m 8\\033[39m UDHR_Chinese_UTF-8.txt             \\033[38;5;246m\\\"\\033[39m\\\\\\\"世界人权宣… UDHR     Chinese  UTF-8         \"                                                                                                                                      ## [12] \"\\033[38;5;250m 9\\033[39m UDHR_English_UTF-16BE.txt          \\033[38;5;246m\\\"\\033[39m\\\\\\\"Unive… UDHR     English  UTF-16BE      \"                                                                                                                                           ## [13] \"\\033[38;5;250m10\\033[39m UDHR_English_UTF-16LE.txt          \\033[38;5;246m\\\"\\033[39m\\\\\\\"Unive… UDHR     English  UTF-16LE      \"                                                                                                                                           ## [14] \"\\033[38;5;250m11\\033[39m UDHR_English_UTF-8.txt             \\033[38;5;246m\\\"\\033[39m\\\\\\\"Unive… UDHR     English  UTF-8         \"                                                                                                                                           ## [15] \"\\033[38;5;250m12\\033[39m UDHR_English_WINDOWS-1252.txt      \\033[38;5;246m\\\"\\033[39m\\\\\\\"Unive… UDHR     English  WINDOWS-1252  \"                                                                                                                                           ## [16] \"\\033[38;5;250m13\\033[39m UDHR_French_ISO-8859-1.txt         \\033[38;5;246m\\\"\\033[39m\\\\\\\"Décla… UDHR     French   ISO-8859-1    \"                                                                                                                                           ## [17] \"\\033[38;5;250m14\\033[39m UDHR_French_UTF-8.txt              \\033[38;5;246m\\\"\\033[39m\\\\\\\"Décla… UDHR     French   UTF-8         \"                                                                                                                                           ## [18] \"\\033[38;5;250m15\\033[39m UDHR_French_WINDOWS-1252.txt       \\033[38;5;246m\\\"\\033[39m\\\\\\\"Décla… UDHR     French   WINDOWS-1252  \"                                                                                                                                           ## [19] \"\\033[38;5;250m16\\033[39m UDHR_German_ISO-8859-1.txt         \\033[38;5;246m\\\"\\033[39m\\\\\\\"Die A… UDHR     German   ISO-8859-1    \"                                                                                                                                           ## [20] \"\\033[38;5;250m17\\033[39m UDHR_German_UTF-8.txt              \\033[38;5;246m\\\"\\033[39m\\\\\\\"Die A… UDHR     German   UTF-8         \"                                                                                                                                           ## [21] \"\\033[38;5;250m18\\033[39m UDHR_German_WINDOWS-1252.txt       \\033[38;5;246m\\\"\\033[39m\\\\\\\"Die A… UDHR     German   WINDOWS-1252  \"                                                                                                                                           ## [22] \"\\033[38;5;250m19\\033[39m UDHR_Greek_CP1253.txt              \\033[38;5;246m\\\"\\033[39m\\\\\\\"ΟΙΚΟΥ… UDHR     Greek    CP1253        \"                                                                                                                                           ## [23] \"\\033[38;5;250m20\\033[39m UDHR_Greek_ISO-8859-7.txt          \\033[38;5;246m\\\"\\033[39m\\\\\\\"ΟΙΚΟΥ… UDHR     Greek    ISO-8859-7    \"                                                                                                                                           ## [24] \"\\033[38;5;250m21\\033[39m UDHR_Greek_UTF-8.txt               \\033[38;5;246m\\\"\\033[39m\\\\\\\"ΟΙΚΟΥ… UDHR     Greek    UTF-8         \"                                                                                                                                           ## [25] \"\\033[38;5;250m22\\033[39m UDHR_Hindi_UTF-8.txt               \\033[38;5;246m\\\"\\033[39m\\\\\\\"मानव अ… UDHR     Hindi    UTF-8         \"                                                                                                                                          ## [26] \"\\033[38;5;250m23\\033[39m UDHR_Icelandic_ISO-8859-1.txt      \\033[38;5;246m\\\"\\033[39m\\\\\\\"Mannr… UDHR     Iceland… ISO-8859-1    \"                                                                                                                                           ## [27] \"\\033[38;5;250m24\\033[39m UDHR_Icelandic_UTF-8.txt           \\033[38;5;246m\\\"\\033[39m\\\\\\\"Mannr… UDHR     Iceland… UTF-8         \"                                                                                                                                           ## [28] \"\\033[38;5;250m25\\033[39m UDHR_Icelandic_WINDOWS-1252.txt    \\033[38;5;246m\\\"\\033[39m\\\\\\\"Mannr… UDHR     Iceland… WINDOWS-1252  \"                                                                                                                                           ## [29] \"\\033[38;5;250m26\\033[39m UDHR_Japanese_CP932.txt            \\033[38;5;246m\\\"\\033[39m\\\\\\\"『世界人権… UDHR     Japanese CP932         \"                                                                                                                                      ## [30] \"\\033[38;5;250m27\\033[39m UDHR_Japanese_ISO-2022-JP.txt      \\033[38;5;246m\\\"\\033[39m\\\\\\\"『世界人権… UDHR     Japanese ISO-2022-JP   \"                                                                                                                                      ## [31] \"\\033[38;5;250m28\\033[39m UDHR_Japanese_UTF-8.txt            \\033[38;5;246m\\\"\\033[39m\\\\\\\"『世界人権… UDHR     Japanese UTF-8         \"                                                                                                                                      ## [32] \"\\033[38;5;250m29\\033[39m UDHR_Japanese_WINDOWS-936.txt      \\033[38;5;246m\\\"\\033[39m\\\\\\\"『世界人権… UDHR     Japanese WINDOWS-936   \"                                                                                                                                      ## [33] \"\\033[38;5;250m30\\033[39m UDHR_Korean_ISO-2022-KR.txt        \\033[38;5;246m\\\"\\033[39m\\\\\\\"세 계 인… UDHR     Korean   ISO-2022-KR   \"                                                                                                                                        ## [34] \"\\033[38;5;250m31\\033[39m UDHR_Korean_UTF-8.txt              \\033[38;5;246m\\\"\\033[39m\\\\\\\"세 계 인… UDHR     Korean   UTF-8         \"                                                                                                                                        ## [35] \"\\033[38;5;250m32\\033[39m UDHR_Russian_ISO-8859-5.txt        \\033[38;5;246m\\\"\\033[39m\\\\\\\"Всеоб… UDHR     Russian  ISO-8859-5    \"                                                                                                                                           ## [36] \"\\033[38;5;250m33\\033[39m UDHR_Russian_KOI8-R.txt            \\033[38;5;246m\\\"\\033[39m\\\\\\\"Всеоб… UDHR     Russian  KOI8-R        \"                                                                                                                                           ## [37] \"\\033[38;5;250m34\\033[39m UDHR_Russian_UTF-8.txt             \\033[38;5;246m\\\"\\033[39m\\\\\\\"Всеоб… UDHR     Russian  UTF-8         \"                                                                                                                                           ## [38] \"\\033[38;5;250m35\\033[39m UDHR_Russian_WINDOWS-1251.txt      \\033[38;5;246m\\\"\\033[39m\\\\\\\"Всеоб… UDHR     Russian  WINDOWS-1251  \"                                                                                                                                           ## [39] \"\\033[38;5;250m36\\033[39m UDHR_Thai_UTF-8.txt                \\033[38;5;246m\\\"\\033[39m\\\\\\\"ปฏิญญา… UDHR     Thai     UTF-8         \"                                                                                                                                           ##  ## $summary ## $summary[[1]] ## NULL ##  ##  ## attr(,\"class\") ## [1] \"trunc_mat\" if (require(\"quanteda\")) { corpus_txts <- corpus(txts) summary(corpus_txts, 5) } ## Corpus consisting of 36 documents, showing 5 documents: ##  ##                                Text Types Tokens Sentences     document ##   IndianTreaty_English_UTF-16LE.txt   619   2578       152 IndianTreaty ##  IndianTreaty_English_UTF-8-BOM.txt   646   3090       150 IndianTreaty ##          UDHR_Arabic_ISO-8859-6.txt   753   1555        86         UDHR ##               UDHR_Arabic_UTF-8.txt   753   1555        86         UDHR ##        UDHR_Arabic_WINDOWS-1256.txt   753   1555        86         UDHR ##  language input_encoding ##   English       UTF-16LE ##   English      UTF-8-BOM ##    Arabic     ISO-8859-6 ##    Arabic          UTF-8 ##    Arabic   WINDOWS-1256"},{"path":"https://readtext.quanteda.io/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kenneth Benoit. Author, maintainer, copyright holder. Adam Obeng. Author. Kohei Watanabe. Contributor. Akitaka Matsuo. Contributor. Paul Nulty. Contributor. Stefan Müller. Contributor.","code":""},{"path":"https://readtext.quanteda.io/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Benoit K, Obeng (2025). readtext: Import Handling Plain Formatted Text Files. R package version 0.92.1, https://readtext.quanteda.io/.","code":"@Manual{,   title = {readtext: Import and Handling for Plain and Formatted Text Files},   author = {Kenneth Benoit and Adam Obeng},   year = {2025},   note = {R package version 0.92.1},   url = {https://readtext.quanteda.io/}, }"},{"path":"https://readtext.quanteda.io/index.html","id":"readtext-import-and-handling-for-plain-and-formatted-text-files","dir":"","previous_headings":"","what":"Import and Handling for Plain and Formatted Text Files","title":"Import and Handling for Plain and Formatted Text Files","text":"R package reading text files various formats, Ken Benoit, Adam Obeng, Paul Nulty, Aki Matsuo, Kohei Watanabe, Stefan Müller.","code":""},{"path":"https://readtext.quanteda.io/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Import and Handling for Plain and Formatted Text Files","text":"readtext one-function package exactly says tin: reads files containing text, along associated document-level metadata, call “docvars”, document variables. Plain text files docvars, forms .csv, .tab, .xml, .json files usually . readtext accepts filemasks, can specify pattern load multiple texts, texts can even multiple types. readtext smart enough process correctly, returning data.frame primary field “text” containing character vector texts, additional columns data.frame found document variables source files. encoding can also challenging issue reading texts, include functions diagnosing encodings file--file basis, allow specify vectorized input encodings read file types individually set (different) encodings. (encoding functions handled stringi package.)","code":""},{"path":"https://readtext.quanteda.io/index.html","id":"how-to-install","dir":"","previous_headings":"","what":"How to Install","title":"Import and Handling for Plain and Formatted Text Files","text":"CRAN GitHub, want latest development version. Linux note: couple dependencies may available linux systems. Debian/Ubuntu try installing packages running commands command line:","code":"install.packages(\"readtext\") # devtools packaged required to install readtext from Github  remotes::install_github(\"quanteda/readtext\") sudo apt-get install libpoppler-cpp-dev   # for antiword"},{"path":"https://readtext.quanteda.io/index.html","id":"demonstration-reading-one-or-more-text-files","dir":"","previous_headings":"","what":"Demonstration: Reading one or more text files","title":"Import and Handling for Plain and Formatted Text Files","text":"readtext supports plain text files (.txt), data form JavaScript Object Notation (.json), comma-tab-separated values (.csv, .tab, .tsv), XML documents (.xml), well PDF, Microsoft Word formatted files document formats (.pdf, .doc, .docx, .odt, .rtf). readtext also handles multiple files file types using instance “glob” expression, files URL archive file (.zip, .tar, .tar.gz, .tar.bz). file formats determined automatically filename extensions. file extension unknown, readtext assume plain text. following command, instance, load files subdirectory txt/UDHR/: files contain multiple documents, comma-separated-value documents, need specify column name containing texts, using text_field argument: complete demonstration, see package vignette.","code":"library(\"readtext\") # get the data directory from readtext DATA_DIR <- system.file(\"extdata/\", package = \"readtext\")  # read in all files from a folder readtext(paste0(DATA_DIR, \"/txt/UDHR/*\")) ## readtext object consisting of 13 documents and 0 docvars. ## # A data frame: 13 × 2 ##   doc_id            text                          ##   <chr>             <chr>                         ## 1 UDHR_chinese.txt  \"\\\"世界人权宣言\\n联合国\\\"...\" ## 2 UDHR_czech.txt    \"\\\"VŠEOBECNÁ \\\"...\"           ## 3 UDHR_danish.txt   \"\\\"Den 10. de\\\"...\"           ## 4 UDHR_english.txt  \"\\\"Universal \\\"...\"           ## 5 UDHR_french.txt   \"\\\"Déclaratio\\\"...\"           ## 6 UDHR_georgian.txt \"\\\"FLFVBFYBC \\\"...\"           ## # ℹ 7 more rows # read in comma-separated values and specify text field readtext(paste0(DATA_DIR, \"/csv/inaugCorpus.csv\"), text_field = \"texts\") ## readtext object consisting of 5 documents and 3 docvars. ## # A data frame: 5 × 5 ##   doc_id            text                 Year President  FirstName ##   <chr>             <chr>               <int> <chr>      <chr>     ## 1 inaugCorpus.csv.1 \"\\\"Fellow-Cit\\\"...\"  1789 Washington George    ## 2 inaugCorpus.csv.2 \"\\\"Fellow cit\\\"...\"  1793 Washington George    ## 3 inaugCorpus.csv.3 \"\\\"When it wa\\\"...\"  1797 Adams      John      ## 4 inaugCorpus.csv.4 \"\\\"Friends an\\\"...\"  1801 Jefferson  Thomas    ## 5 inaugCorpus.csv.5 \"\\\"Proceeding\\\"...\"  1805 Jefferson  Thomas"},{"path":[]},{"path":"https://readtext.quanteda.io/index.html","id":"with-quanteda","dir":"","previous_headings":"Inter-operability with other packages","what":"With quanteda","title":"Import and Handling for Plain and Formatted Text Files","text":"readtext originally developed early versions quanteda package quantitative analysis textual data. quanteda’s corpus constructor recognizes data.frame format returned readtext(), can construct corpus directly readtext object, preserving docvars meta-data.","code":"library(\"quanteda\") ## Package version: 4.3.1 ## Unicode version: 14.0 ## ICU version: 71.1 ## Parallel computing: 10 of 10 threads used. ## See https://quanteda.io for tutorials and examples. ##  ## Attaching package: 'quanteda' ## The following object is masked from 'package:readtext': ##  ##     texts # read in comma-separated values with readtext rt_csv <- readtext(paste0(DATA_DIR, \"/csv/inaugCorpus.csv\"), text_field = \"texts\") # create quanteda corpus corpus_csv <- corpus(rt_csv) summary(corpus_csv, 5) ## Corpus consisting of 5 documents, showing 5 documents: ##  ##               Text Types Tokens Sentences Year  President FirstName ##  inaugCorpus.csv.1   625   1540        23 1789 Washington    George ##  inaugCorpus.csv.2    96    147         4 1793 Washington    George ##  inaugCorpus.csv.3   826   2578        37 1797      Adams      John ##  inaugCorpus.csv.4   717   1927        41 1801  Jefferson    Thomas ##  inaugCorpus.csv.5   804   2381        45 1805  Jefferson    Thomas"},{"path":"https://readtext.quanteda.io/index.html","id":"text-interchange-format-compatibility","dir":"","previous_headings":"Inter-operability with other packages","what":"Text Interchange Format compatibility","title":"Import and Handling for Plain and Formatted Text Files","text":"readtext returns data.frame formatted per corpus structure Text Interchange Format, can easily used packages can accept corpus data.frame format. want named character object, readtext also defines .character() method inputs data.frame returns just named character vector texts, conforming TIF definition character version corpus.","code":""},{"path":"https://readtext.quanteda.io/reference/add_docid.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the docid for multi-document objects — add_docid","title":"Set the docid for multi-document objects — add_docid","text":"Set docid multi-document objects","code":""},{"path":"https://readtext.quanteda.io/reference/add_docid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the docid for multi-document objects — add_docid","text":"","code":"add_docid(x, path, docid_field)"},{"path":"https://readtext.quanteda.io/reference/add_docid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the docid for multi-document objects — add_docid","text":"x data.frame; contains texts document variables path character; file path x created; use error message docid_field numeric character; indicate position text column x","code":""},{"path":"https://readtext.quanteda.io/reference/as.character.readtext.html","id":null,"dir":"Reference","previous_headings":"","what":"return only the texts from a readtext object — as.character.readtext","title":"return only the texts from a readtext object — as.character.readtext","text":"accessor function return texts readtext object character vector, names matching document names.","code":""},{"path":"https://readtext.quanteda.io/reference/as.character.readtext.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"return only the texts from a readtext object — as.character.readtext","text":"","code":"# S3 method for class 'readtext' as.character(x, ...)"},{"path":"https://readtext.quanteda.io/reference/as.character.readtext.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"return only the texts from a readtext object — as.character.readtext","text":"x readtext object whose texts extracted ... arguments passed methods","code":""},{"path":"https://readtext.quanteda.io/reference/basename_unique.html","id":null,"dir":"Reference","previous_headings":"","what":"Return basenames that are unique — basename_unique","title":"Return basenames that are unique — basename_unique","text":"Return basenames unique","code":""},{"path":"https://readtext.quanteda.io/reference/basename_unique.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return basenames that are unique — basename_unique","text":"","code":"basename_unique(x, path_only = FALSE)"},{"path":"https://readtext.quanteda.io/reference/basename_unique.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return basenames that are unique — basename_unique","text":"x character vector; file paths path_only logical; TRUE, return unique part path","code":""},{"path":"https://readtext.quanteda.io/reference/basename_unique.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return basenames that are unique — basename_unique","text":"","code":"files <- c(\"../data/glob/subdir1/test.txt\", \"../data/glob/subdir2/test.txt\") readtext:::basename_unique(files) #> [1] \"subdir1\" \"subdir2\" # [1] \"subdir1/test.txt\" \"subdir2/test.txt\" readtext:::basename_unique(files, path_only = TRUE) #> [1] \"subdir1\" \"subdir2\" # [1] \"subdir1\" \"subdir2\" readtext:::basename_unique(c(\"../data/test1.txt\", \"../data/test2.txt\")) #> [1] \"test1.txt\" \"test2.txt\" # [1] \"test1.txt\" \"test2.txt\""},{"path":"https://readtext.quanteda.io/reference/cache_remote.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to cache remote file — cache_remote","title":"Internal function to cache remote file — cache_remote","text":"Internal function cache remote file","code":""},{"path":"https://readtext.quanteda.io/reference/cache_remote.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to cache remote file — cache_remote","text":"","code":"cache_remote(url, ignore_missing, cache, basename = NULL, verbosity = 1)"},{"path":"https://readtext.quanteda.io/reference/cache_remote.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to cache remote file — cache_remote","text":"url location remote file ignore_missing TRUE, warns download status cache TRUE, save file system's temporary folder load next time basename name temporary file preserve file extensions. NULL, random string used. verbosity 0: output errors 1: output errors warnings (default) 2: output brief summary message 3: output detailed file-related messages","code":""},{"path":"https://readtext.quanteda.io/reference/data_char_encodedtexts.html","id":null,"dir":"Reference","previous_headings":"","what":"encoded texts for testing — data_char_encodedtexts","title":"encoded texts for testing — data_char_encodedtexts","text":"data_char_encodedtexts 10-element character vector 10 different encodings","code":""},{"path":"https://readtext.quanteda.io/reference/data_char_encodedtexts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"encoded texts for testing — data_char_encodedtexts","text":"","code":"data_char_encodedtexts"},{"path":"https://readtext.quanteda.io/reference/data_char_encodedtexts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"encoded texts for testing — data_char_encodedtexts","text":"object class character length 10.","code":""},{"path":"https://readtext.quanteda.io/reference/data_char_encodedtexts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"encoded texts for testing — data_char_encodedtexts","text":"","code":"if (FALSE) { # \\dontrun{ Encoding(data_char_encodedtexts) data.frame(labelled = names(data_char_encodedtexts),             detected = encoding(data_char_encodedtexts)$all) } # }"},{"path":"https://readtext.quanteda.io/reference/data_files_encodedtexts.html","id":null,"dir":"Reference","previous_headings":"","what":"a .zip file of texts containing a variety of differently encoded texts — data_files_encodedtexts","title":"a .zip file of texts containing a variety of differently encoded texts — data_files_encodedtexts","text":"set translations Universal Declaration Human Rights, plus one two miscellaneous texts, testing text input functions need translate different input encodings.","code":""},{"path":"https://readtext.quanteda.io/reference/data_files_encodedtexts.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"a .zip file of texts containing a variety of differently encoded texts — data_files_encodedtexts","text":"Universal Declaration Human Rights resources, https://www.un.org/en/-us/universal-declaration--human-rights","code":""},{"path":"https://readtext.quanteda.io/reference/data_files_encodedtexts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"a .zip file of texts containing a variety of differently encoded texts — data_files_encodedtexts","text":"","code":"if (FALSE) # unzip the files to a temporary directory FILEDIR <- tempdir() unzip(system.file(\"extdata\", \"data_files_encodedtexts.zip\", package = \"readtext\"),        exdir = FILEDIR) #> Error: object 'FILEDIR' not found  # get encoding from filename filenames <- list.files(FILEDIR, \"\\\\.txt$\") #> Error: object 'FILEDIR' not found # strip the extension filenames <- gsub(\".txt$\", \"\", filenames) #> Error: object 'filenames' not found parts <- strsplit(filenames, \"_\") #> Error: object 'filenames' not found fileencodings <- sapply(parts, \"[\", 3) #> Error: object 'parts' not found fileencodings #> Error: object 'fileencodings' not found  # find out which conversions are unavailable (through iconv()) cat(\"Encoding conversions not available for this platform:\") #> Encoding conversions not available for this platform: notAvailableIndex <- which(!(fileencodings %in% iconvlist())) #> Error: object 'fileencodings' not found fileencodings[notAvailableIndex] #> Error: object 'fileencodings' not found  # try readtext require(quanteda) #> Loading required package: quanteda #> Package version: 4.3.1 #> Unicode version: 14.0 #> ICU version: 71.1 #> Parallel computing: 10 of 10 threads used. #> See https://quanteda.io for tutorials and examples. #>  #> Attaching package: ‘quanteda’ #> The following object is masked from ‘package:readtext’: #>  #>     texts txts <- readtext(paste0(FILEDIR, \"/\", \"*.txt\")) #> Error: object 'FILEDIR' not found substring(texts(txts)[1], 1, 80) # gibberish #> Error: object 'txts' not found substring(texts(txts)[4], 1, 80) # hex #> Error: object 'txts' not found substring(texts(txts)[40], 1, 80) # hex #> Error: object 'txts' not found  # read them in again txts <- readtext(paste0(FILEDIR,  \"/\", \"*.txt\"), encoding = fileencodings) #> Error: object 'FILEDIR' not found substring(texts(txts)[1], 1, 80)  # English #> Error: object 'txts' not found substring(texts(txts)[4], 1, 80)  # Arabic, looking good  #> Error: object 'txts' not found substring(texts(txts)[40], 1, 80) # Cyrillic, looking good #> Error: object 'txts' not found substring(texts(txts)[7], 1, 80)  # Chinese, looking good #> Error: object 'txts' not found substring(texts(txts)[26], 1, 80) # Hindi, looking good #> Error: object 'txts' not found  txts <- readtext(paste0(FILEDIR, \"/\", \"*.txt\"), encoding = fileencodings,                   docvarsfrom = \"filenames\",                    docvarnames = c(\"document\", \"language\", \"inputEncoding\")) #> Error: object 'FILEDIR' not found encodingCorpus <- corpus(txts, source = \"Created by encoding-tests.R\")  #> Error: object 'txts' not found summary(encodingCorpus) #> Error: object 'encodingCorpus' not found  # \\dontrun{}"},{"path":"https://readtext.quanteda.io/reference/encoding.html","id":null,"dir":"Reference","previous_headings":"","what":"detect the encoding of texts — encoding","title":"detect the encoding of texts — encoding","text":"Detect encoding texts character readtext object report likely encoding document.  Useful detecting encoding input texts, source encoding can (re)specified inputting set texts using readtext(), prior constructing corpus.","code":""},{"path":"https://readtext.quanteda.io/reference/encoding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"detect the encoding of texts — encoding","text":"","code":"encoding(x, verbose = TRUE, ...)"},{"path":"https://readtext.quanteda.io/reference/encoding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"detect the encoding of texts — encoding","text":"x character vector, corpus, readtext object whose texts' encodings detected. verbose FALSE, print diagnostic report ... additional arguments passed stri_enc_detect","code":""},{"path":"https://readtext.quanteda.io/reference/encoding.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"detect the encoding of texts — encoding","text":"Based stri_enc_detect, turn based ICU libraries.  See ICU User Guide, https://unicode-org.github.io/icu/userguide/.","code":""},{"path":"https://readtext.quanteda.io/reference/encoding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"detect the encoding of texts — encoding","text":"","code":"if (FALSE) encoding(data_char_encodedtexts) # show detected value for each text, versus known encoding data.frame(labelled = names(data_char_encodedtexts),             detected = encoding(data_char_encodedtexts)$all) #> Probable encoding: UTF-8 #>    (but other encodings also detected) #>   Encoding proportions:  #> [****************--------........~~~~~~~aaaaaaabbbbbcccccddddd] #>  #>   Samples of the first text as: #>   [*] UTF-8          “8-bit” oœncodings are passé. €0. Hyphen-ate. Tilde ~ em das #>   [-] windows-1252   â€œ8-bitâ€ oÅ“ncodings are passÃ©. â‚¬0. Hyphen-ate. Tilde  #>   [.] ISO-8859-6     ق8-bitق oإncodings are passأ�. ق،0. Hyphen-ate. Tilde  #>   [~] ISO-8859-2     â8-bitâ oĹncodings are passĂŠ. âŹ0. Hyphen-ate. Tilde  #>   [a] ISO-8859-1     â8-bitâ oÅncodings are passÃ©. â¬0. Hyphen-ate. Tilde  #>   [b] ISO-8859-5     т8-bitт oХncodings are passУЉ. тЌ0. Hyphen-ate. Tilde  #>   [c] windows-1251   вЂњ8-bitвЂќ oЕ“ncodings are passГ©. в‚¬0. Hyphen-ate. Tilde  #>   [d] KOI8-R         Б─°8-bitБ─² oе⌠ncodings are passц╘. Б┌╛0. Hyphen-ate. Tilde  #>        labelled     detected #> 1         UTF-8        UTF-8 #> 2    ISO-8859-1   ISO-8859-1 #> 3  windows-1252 windows-1252 #> 4      macroman windows-1252 #> 5    ISO-8859-2   ISO-8859-2 #> 6    ISO-8859-6   ISO-8859-6 #> 7    ISO-8859-5   ISO-8859-5 #> 8  windows-1251 windows-1251 #> 9        KOI8-R       KOI8-R #> 10        ASCII   ISO-8859-1  # Russian text, Windows-1251 myreadtext <- readtext(\"https://kenbenoit.net/files/01_er_5.txt\") encoding(myreadtext) #> readtext object consisting of 1 document and 0 docvars. #> # A data frame: 1 × 2 #>   doc_id      text                                              #>   <chr>       <chr>                                             #> 1 01_er_5.txt \"\\\"\\xd1\\xf2\\xe5\\xed\\xee\\xe3\\xf0\\xe0\\xec\\xec\\\"...\" #> Probable encoding: windows-1251 #>   # \\dontrun{}"},{"path":"https://readtext.quanteda.io/reference/get_nexis_html.html","id":null,"dir":"Reference","previous_headings":"","what":"extract texts and meta data from Nexis HTML files — get_nexis_html","title":"extract texts and meta data from Nexis HTML files — get_nexis_html","text":"extract headings, body texts meta data (date, byline, length, section, edition) items HTML files downloaded scraper.","code":""},{"path":"https://readtext.quanteda.io/reference/get_nexis_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract texts and meta data from Nexis HTML files — get_nexis_html","text":"","code":"get_nexis_html(path, paragraph_separator = \"\\n\\n\", verbosity, ...)"},{"path":"https://readtext.quanteda.io/reference/get_nexis_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract texts and meta data from Nexis HTML files — get_nexis_html","text":"path either path HTML file directory contains HTML files paragraph_separator character separate paragraphs body texts verbosity 0: output errors 1: output errors warnings (default) 2: output brief summary message 3: output detailed file-related messages ... trap extra arguments","code":""},{"path":"https://readtext.quanteda.io/reference/get_nexis_html.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract texts and meta data from Nexis HTML files — get_nexis_html","text":"","code":"if (FALSE) { # \\dontrun{ irt <- readtext:::get_nexis_html('tests/data/nexis/irish-times_1995-06-12_0001.html') afp <- readtext:::get_nexis_html('tests/data/nexis/afp_2013-03-12_0501.html') gur <- readtext:::get_nexis_html('tests/data/nexis/guardian_1986-01-01_0001.html') sun <- readtext:::get_nexis_html('tests/data/nexis/sun_2000-11-01_0001.html') spg <- readtext:::get_nexis_html('tests/data/nexis/spiegel_2012-02-01_0001.html',                                    language_date = 'german')  all <- readtext('tests/data/nexis', source = 'nexis') all <- readtext('tests/data/nexis', source = 'nexis') } # }"},{"path":"https://readtext.quanteda.io/reference/get_temp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get path to temporary file or directory — get_temp","title":"Get path to temporary file or directory — get_temp","text":"Get path temporary file directory","code":""},{"path":"https://readtext.quanteda.io/reference/get_temp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get path to temporary file or directory — get_temp","text":"","code":"get_temp(prefix = \"readtext-\", temp_dir = NULL, directory = FALSE, seed = NULL)"},{"path":"https://readtext.quanteda.io/reference/get_temp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get path to temporary file or directory — get_temp","text":"prefix string appended random file directory names. temp_dir path temporary directory. NULL, value tempdir() used. directory logical; TRUE, temporary directory created. seed seed value digest::digest. NULL, random value used.","code":""},{"path":"https://readtext.quanteda.io/reference/impute_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect and set variable types automatically — impute_types","title":"Detect and set variable types automatically — impute_types","text":"Detect set variable types similar way read.csv() . used imported data.frame characters.","code":""},{"path":"https://readtext.quanteda.io/reference/impute_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect and set variable types automatically — impute_types","text":"","code":"impute_types(x)"},{"path":"https://readtext.quanteda.io/reference/impute_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect and set variable types automatically — impute_types","text":"x data.frame; columns characters vectors","code":""},{"path":"https://readtext.quanteda.io/reference/print.readtext.html","id":null,"dir":"Reference","previous_headings":"","what":"print method for a readtext object — print.readtext","title":"print method for a readtext object — print.readtext","text":"Print readtext object nicely formatted way.","code":""},{"path":"https://readtext.quanteda.io/reference/print.readtext.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print method for a readtext object — print.readtext","text":"","code":"# S3 method for class 'readtext' print(x, n = 6L, text_width = 10L, ...)"},{"path":"https://readtext.quanteda.io/reference/print.readtext.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print method for a readtext object — print.readtext","text":"x readtext object printed n single integer, number rows readtext object print. text_width number characters display text field ... used ","code":""},{"path":"https://readtext.quanteda.io/reference/readtext-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and handling for plain and formatted text files — readtext-package","title":"Import and handling for plain and formatted text files — readtext-package","text":"set functions  importing handling text files formatted text files additional meta-data, including .csv, .tab, .json, .xml, .xls, .xlsx, others.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import and handling for plain and formatted text files — readtext-package","text":"readtext makes easy import text files various formats, including using operating system filemasks load groups files based glob pattern matches, including files multiple directories sub-directories. readtext can also read multiple files R compressed archive files .gz, .zip, .tar.gz, etc.  Finally readtext reads document-level meta-data associated texts, texts format (e.g. .csv, .json) includes additional, non-textual data.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext-package.html","id":"package-options","dir":"Reference","previous_headings":"","what":"Package options","title":"Import and handling for plain and formatted text files — readtext-package","text":"readtext_verbosity Default verbosity messages produced reading files.  See readtext().","code":""},{"path":[]},{"path":"https://readtext.quanteda.io/reference/readtext-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Import and handling for plain and formatted text files — readtext-package","text":"Ken Benoit, Adam Obeng, Paul Nulty","code":""},{"path":"https://readtext.quanteda.io/reference/readtext.html","id":null,"dir":"Reference","previous_headings":"","what":"read a text file(s) — readtext","title":"read a text file(s) — readtext","text":"Read texts () associated document-level meta-data one source files. text source files come textual component files, document-level metadata (\"docvars\") come either file contents filenames.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read a text file(s) — readtext","text":"","code":"readtext(   file,   ignore_missing_files = FALSE,   text_field = NULL,   docid_field = NULL,   docvarsfrom = c(\"metadata\", \"filenames\", \"filepaths\"),   dvsep = \"_\",   docvarnames = NULL,   encoding = NULL,   source = NULL,   cache = TRUE,   verbosity = readtext_options(\"verbosity\"),   ... )"},{"path":"https://readtext.quanteda.io/reference/readtext.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read a text file(s) — readtext","text":"file complete filename(s) read. designed automagically handle number common scenarios, value can \"glob\"-type wildcard value.  Currently available filetypes : Single file formats: txt plain text files: -called structured text files, describe texts metadata: structured text filetypes, column, field, node contains text must specified text_field parameter, fields treated docvars. json data form JavaScript Object Notation, consisting texts optionally additional docvars. supported formats : single JSON object per file line-delimited JSON, one object per line line-delimited JSON, format produced Twitter stream. type file special handling simplifies Twitter format docvars.  correct format JSON file automatically detected. csv,tab,tsv comma- tab-separated values html HTML documents, including specialized formats known sources, Nexis-formatted HTML.  See source parameter . xml XML documents supported – kind can read xml2::read_xml() navigated xml2::xml_find_all(). xml files, additional argument collapse may passed ... names character(s) use appending different text elements together. pdf pdf formatted files, converted pdftools. odt Open Document Text formatted files. doc, docx Microsoft Word formatted files. rtf Rich Text Files. wildcard value valid pathname wildcard (\"glob\") expression can expanded operating system.  may consist multiple file types. URL remote downloaded loaded zip,tar,tar.gz,tar.bz archive file, unzipped. contained files must either top level single directory. Archives, remote URLs glob patterns can resolve filetypes, , example, remote URL zip file contained Twitter JSON files. ignore_missing_files FALSE, file argument resolve existing file, error thrown. Note can happen number ways, including passing path file exist, empty archive file, glob pattern matches files. text_field, docid_field variable (column) name column number indicating find texts form documents corpus identifiers.  must specified file types .csv, .json, .xls/.xlsx files.  XML files, XPath expression can specified. docvarsfrom used specify docvars taken filenames, readtext inputs filenames elements filenames document variables, separated delimiter (dvsep).  allows easy assignment docvars filenames 1789-Washington.txt, 1793-Washington, etc. dvsep meta-data embedded text file header (headers). docvarsfrom set \"filepaths\", consider full path file, just filename. dvsep separator (regular expression character string) used filenames delimit docvar elements  docvarsfrom=\"filenames\" docvarsfrom=\"filepaths\" used docvarnames character vector variable names docvars, docvarsfrom specified.  argument used, default docvar names used (docvar1, docvar2, ...). encoding vector: either encoding files, one encoding files source used specify specific formats input file types, JSON HTML. Currently supported types \"twitter\" JSON \"nexis\" HTML. cache TRUE, save remote file temporary folder. used file URL. verbosity 0: output errors 1: output errors warnings (default) 2: output brief summary message 3: output detailed file-related messages ... additional arguments passed low-level file reading function, file(), fread, etc.  Useful specifying input encoding option, specified give iconv().  See Encoding section file details.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read a text file(s) — readtext","text":"data.frame consisting columns doc_id text contain document identifier texts respectively, additional columns consisting document-level variables either found file containing texts, created readtext call.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"read a text file(s) — readtext","text":"","code":"if (FALSE) { # \\dontrun{ ## get the data directory if (!interactive()) pkgload::load_all() DATA_DIR <- system.file(\"extdata/\", package = \"readtext\")  ## read in some text data # all UDHR files (rt1 <- readtext(paste0(DATA_DIR, \"/txt/UDHR/*\")))  # manifestos with docvars from filenames (rt2 <- readtext(paste0(DATA_DIR, \"/txt/EU_manifestos/*.txt\"),                  docvarsfrom = \"filenames\",                   docvarnames = c(\"unit\", \"context\", \"year\", \"language\", \"party\"),                  encoding = \"LATIN1\"))                   # recurse through subdirectories (rt3 <- readtext(paste0(DATA_DIR, \"/txt/movie_reviews/*\"),                   docvarsfrom = \"filepaths\", docvarnames = \"sentiment\"))  ## read in csv data (rt4 <- readtext(paste0(DATA_DIR, \"/csv/inaugCorpus.csv\")))  ## read in tab-separated data (rt5 <- readtext(paste0(DATA_DIR, \"/tsv/dailsample.tsv\"), text_field = \"speech\"))  ## read in JSON data (rt6 <- readtext(paste0(DATA_DIR, \"/json/inaugural_sample.json\"), text_field = \"texts\"))  ## read in pdf data # UNHDR (rt7 <- readtext(paste0(DATA_DIR, \"/pdf/UDHR/*.pdf\"),                   docvarsfrom = \"filenames\",                   docvarnames = c(\"document\", \"language\"))) Encoding(rt7$text)  ## read in Word data (.doc) (rt8 <- readtext(paste0(DATA_DIR, \"/word/*.doc\"))) Encoding(rt8$text)  ## read in Word data (.docx) (rt9 <- readtext(paste0(DATA_DIR, \"/word/*.docx\"))) Encoding(rt9$text)  ## use elements of path and filename as docvars (rt10 <- readtext(paste0(DATA_DIR, \"/pdf/UDHR/*.pdf\"),                    docvarsfrom = \"filepaths\", dvsep = \"[/_.]\")) } # }"},{"path":"https://readtext.quanteda.io/reference/readtext_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Get or set package options for readtext — readtext_options","title":"Get or set package options for readtext — readtext_options","text":"Get set global options affecting functions across readtext.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get or set package options for readtext — readtext_options","text":"","code":"readtext_options(..., reset = FALSE, initialize = FALSE)"},{"path":"https://readtext.quanteda.io/reference/readtext_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get or set package options for readtext — readtext_options","text":"... options set, key-value pair, options(). may list valid key-value pairs, useful setting group options (see examples). reset logical; TRUE, reset readtext options default values initialize logical; TRUE, reset readtext options already defined.  Used setting initial values defined previously, .Rprofile.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get or set package options for readtext — readtext_options","text":"called using key = value pair (key can label quoted character name)), option set TRUE returned invisibly. called arguments, named list package options returned. called reset = TRUE argument, arguments options reset default values, TRUE returned invisibly.","code":""},{"path":"https://readtext.quanteda.io/reference/readtext_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get or set package options for readtext — readtext_options","text":"Currently available options : verbosity Default verbosity messages produced reading files.  See readtext().","code":""},{"path":"https://readtext.quanteda.io/reference/readtext_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get or set package options for readtext — readtext_options","text":"","code":"if (FALSE) { # \\dontrun{ # save the current options (opt <- readtext_options())  # set higher verbosity readtext_options(verbosity = 3)  # read something in here if (!interactive()) pkgload::load_all() DATA_DIR <- system.file(\"extdata/\", package = \"readtext\") readtext(paste0(DATA_DIR, \"/txt/UDHR/*\"))  # reset to saved options readtext_options(opt) } # }"},{"path":"https://readtext.quanteda.io/reference/sort_fields.html","id":null,"dir":"Reference","previous_headings":"","what":"Move text to the first column and set types to document variables — sort_fields","title":"Move text to the first column and set types to document variables — sort_fields","text":"Move text first column set types document variables","code":""},{"path":"https://readtext.quanteda.io/reference/sort_fields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move text to the first column and set types to document variables — sort_fields","text":"","code":"sort_fields(x, path, text_field, impute_types = TRUE)"},{"path":"https://readtext.quanteda.io/reference/sort_fields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move text to the first column and set types to document variables — sort_fields","text":"x data.frame; contains texts document variables path character; file path x created; use error message text_field numeric character; indicate position text column x impute_types logical; TRUE, set types variables automatically","code":""},{"path":"https://readtext.quanteda.io/reference/texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Get corpus texts [deprecated] — texts","title":"Get corpus texts [deprecated] — texts","text":"Get texts readtext object.","code":""},{"path":"https://readtext.quanteda.io/reference/texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get corpus texts [deprecated] — texts","text":"","code":"texts(x, ...)  # S3 method for class 'readtext' texts(x, ...)"},{"path":"https://readtext.quanteda.io/reference/texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get corpus texts [deprecated] — texts","text":"x readtext object ... used","code":""},{"path":"https://readtext.quanteda.io/reference/texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get corpus texts [deprecated] — texts","text":"character vector texts corpus","code":""},{"path":"https://readtext.quanteda.io/reference/texts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get corpus texts [deprecated] — texts","text":"function deprecated. Use .character.readtext() turn readtext object simple named character vector documents.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v091","dir":"Changelog","previous_headings":"","what":"readtext v0.91","title":"readtext v0.91","text":"CRAN release: 2024-02-23 Completes changes compatibility quanteda 4.0.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v090","dir":"Changelog","previous_headings":"","what":"readtext v0.90","title":"readtext v0.90","text":"CRAN release: 2023-06-03 Removes deprecated quanteda functions: docvars(), docnames(), texts().","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v082","dir":"Changelog","previous_headings":"","what":"readtext v0.82","title":"readtext v0.82","text":"CRAN release: 2023-04-06 Moves quanteda functions package: docvars(), docnames(), texts() Updates print method use pillar instead tibble Modernizes testthat syntax.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v081","dir":"Changelog","previous_headings":"","what":"readtext v0.81","title":"readtext v0.81","text":"CRAN release: 2021-07-14 Fixed problem examples breaking CRAN checks Solaris. Changed documentation markdown.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v080","dir":"Changelog","previous_headings":"","what":"readtext v0.80","title":"readtext v0.80","text":"CRAN release: 2020-09-22 Updated compatibility newer versions readODS pdftools packages. “.DOCX” (uppercase filename extensions) now handled correctly.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v076","dir":"Changelog","previous_headings":"","what":"readtext v0.76","title":"readtext v0.76","text":"CRAN release: 2020-03-04 Fixed bug assignment function document IDs caused failure reading file text_field specified docid_field.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v075","dir":"Changelog","previous_headings":"","what":"readtext v0.75","title":"readtext v0.75","text":"CRAN release: 2019-06-26 Added docid_field argument columnar data (#155).","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v074","dir":"Changelog","previous_headings":"","what":"readtext v0.74","title":"readtext v0.74","text":"CRAN release: 2019-05-08 Added support RTF format (.rtf).","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v072","dir":"Changelog","previous_headings":"","what":"readtext v0.7.2","title":"readtext v0.7.2","text":"Added support Open Document format (.odt).","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v072-1","dir":"Changelog","previous_headings":"","what":"readtext v0.7.2","title":"readtext v0.7.2","text":"Fixed #138, caused single-column .csv-type files load correctly.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v071","dir":"Changelog","previous_headings":"","what":"readtext v0.7.1","title":"readtext v0.7.1","text":"Added readtext_options(), fixes #123.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v070","dir":"Changelog","previous_headings":"","what":"readtext v0.7.0","title":"readtext v0.7.0","text":"Move xml2 instead older XML package. Change options settings package can used without loading first.","code":""},{"path":"https://readtext.quanteda.io/news/index.html","id":"readtext-v050","dir":"Changelog","previous_headings":"","what":"readtext v0.5.0","title":"readtext v0.5.0","text":"First CRAN release.","code":""}]
